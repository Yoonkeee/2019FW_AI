{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression - preprocessing",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFTTHS-yBtGk",
        "colab_type": "text"
      },
      "source": [
        "# **imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vFGEez2Bsir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import struct\n",
        "import numpy as np\n",
        "from time import time\n",
        "from numpy import random as rnd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as pyplot\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import make_scorer\n",
        "from IPython.display import clear_output\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "to1p5XZ2BccS",
        "colab_type": "text"
      },
      "source": [
        "# **Download MNIST Files** (working at google colaboratory)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyeE90VzBSOV",
        "colab_type": "code",
        "outputId": "38e6eb62-c6c1-481d-e955-5906a67e3edd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# !wget http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
        "# !wget http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
        "# !wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
        "# !wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
        "\n",
        "# !gzip -d train-images.idx3-ubyte.gz\n",
        "# !gzip -d train-labels.idx1-ubyte.gz\n",
        "# !gzip -d t10k-images.idx3-ubyte.gz\n",
        "# !gzip -d t10k-labels.idx1-ubyte.gz\n",
        "# clear_output()\n",
        "# print()\n",
        "# #!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eLdvxw-Ba3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "Loosely inspired by http://abel.ee.ucla.edu/cvxopt/_downloads/mnist.py\n",
        "which is GPL licensed.\n",
        "\"\"\"\n",
        "def read(dataset = \"training\", path = \"C:/datas/\"):\n",
        "    \"\"\"\n",
        "    Python function for importing the MNIST data set.  It returns an iterator\n",
        "    of 2-tuples with the first element being the label and the second element\n",
        "    being a numpy.uint8 2D array of pixel data for the given image.\n",
        "    \"\"\"\n",
        "\n",
        "    if dataset is \"training\":\n",
        "        fname_img = os.path.join(path, 'train-images.idx3-ubyte')\n",
        "        fname_lbl = os.path.join(path, 'train-labels.idx1-ubyte')\n",
        "        print('read() training!!')\n",
        "    elif dataset is \"testing\":\n",
        "        fname_img = os.path.join(path, 't10k-images.idx3-ubyte')\n",
        "        fname_lbl = os.path.join(path, 't10k-labels.idx1-ubyte')\n",
        "        print('read() testing!!')\n",
        "    else:\n",
        "        raise Exception(\"dataset must be 'testing' or 'training'\")\n",
        "\n",
        "    # Load everything in some numpy arrays\n",
        "    with open(fname_lbl, 'rb') as flbl:\n",
        "        magic, num = struct.unpack(\">II\", flbl.read(8))\n",
        "        lbl = np.fromfile(flbl, dtype=np.int8)\n",
        "\n",
        "    with open(fname_img, 'rb') as fimg:\n",
        "        magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16))\n",
        "        img = np.fromfile(fimg, dtype=np.uint8).reshape(len(lbl), rows, cols)\n",
        "\n",
        "    get_img = lambda idx: (lbl[idx], img[idx])\n",
        "\n",
        "    # Create an iterator which returns each image in turn\n",
        "    for i in range(len(lbl)):\n",
        "        yield get_img(i)\n",
        "\n",
        "def show(image):\n",
        "    \"\"\"\n",
        "    Render a given numpy.uint8 2D array of pixel data.\n",
        "    \"\"\"\n",
        "    from matplotlib import pyplot\n",
        "    import matplotlib as mpl\n",
        "    fig = pyplot.figure()\n",
        "    ax = fig.add_subplot(1,1,1)\n",
        "    imgplot = ax.imshow(image, cmap=mpl.cm.Greys)\n",
        "    imgplot.set_interpolation('nearest')\n",
        "    ax.xaxis.set_ticks_position('top')\n",
        "    ax.yaxis.set_ticks_position('left')\n",
        "read()\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV4_YWSjGKKB",
        "colab_type": "text"
      },
      "source": [
        "# **Reading training set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Fx6xeqfBnV7",
        "colab_type": "code",
        "outputId": "b5bee8ca-d488-4691-d82e-02dacb93e349",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# read dataset fron file.\n",
        "\n",
        "#tr = list(read(\"training\", \"/content/gdrive/My Drive/\"))\n",
        "#ts = list(read(\"testing\",\"/content/gdrive/My Drive/\"))\n",
        "tr = list(read(\"training\", \"C:/datas\"))\n",
        "ts = list(read(\"testing\", \"C:/datas\"))\n",
        "\n",
        "\n",
        "LIMIT = 5000\n",
        "X_train = np.array(list(zip(*tr))[1][:LIMIT])\n",
        "y_train = np.array(list(zip(*tr))[0][:LIMIT])\n",
        "\n",
        "X_test = np.array(list(zip(*ts))[1][:LIMIT])\n",
        "y_test = np.array(list(zip(*ts))[0][:LIMIT])\n",
        "\n",
        "#print(X_train.shape)\n",
        "#print(y_train.shape)\n",
        "#print(X_test.shape)\n",
        "#print(y_test.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "read() training!!\n",
            "read() testing!!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7I9l0qbFzPn",
        "colab_type": "text"
      },
      "source": [
        "# **Split Set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrkrf8lyFykz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_set(d = None):\n",
        "  if d == None:\n",
        "    return train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "  elif d == 'scale':\n",
        "    return train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "  \n",
        "  print(X_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZNcQ1hHJh_A",
        "colab_type": "text"
      },
      "source": [
        "# **Compare [Non-scaled, Scaled] sets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2UceeLHBXk2",
        "colab_type": "code",
        "outputId": "f66cab27-4ae3-48b2-f9b4-d6fc08a2df7f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 28, 28)\n",
            "(5000,)\n",
            "(5000,)\n",
            "(5000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urbtPbwrBQZu",
        "colab_type": "code",
        "outputId": "8a80e863-d408-426a-8435-603c555973b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "training_size = len(X_train)\n",
        "testing_size = len(X_test)\n",
        "X_train = X_train.reshape(training_size, 784)\n",
        "X_test = X_test.reshape(testing_size, 784)\n",
        "clf = LogisticRegression(C=50,\n",
        "                         multi_class='multinomial',\n",
        "                         penalty='l2', solver='saga', tol=0.1)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "clear_output()\n",
        "y_predict = clf.predict(X_test)\n",
        "\n",
        "print('Training size : %d Testing Size : %d' %(training_size, testing_size))\n",
        "print(f'normal score: {accuracy_score(y_test,clf.predict(X_test))}')\n",
        "\n",
        "y_predict = clf.predict(X_test)\n",
        "# cm = confusion_matrix(y_test, y_predict)\n",
        "print(classification_report(y_test, y_predict, \n",
        "                            target_names=['0','1','2','3','4','5','6','7','8','9']))\n",
        "\n",
        "\n",
        "# print(f'normal score: {accuracy_score(y_test, clf.predict(X_test))}')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training size : 5000 Testing Size : 5000\n",
            "normal score: 0.8754\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.94       460\n",
            "           1       0.92      0.98      0.95       571\n",
            "           2       0.90      0.83      0.86       530\n",
            "           3       0.86      0.86      0.86       500\n",
            "           4       0.86      0.91      0.88       500\n",
            "           5       0.84      0.81      0.83       456\n",
            "           6       0.92      0.87      0.89       462\n",
            "           7       0.88      0.84      0.86       512\n",
            "           8       0.84      0.81      0.83       489\n",
            "           9       0.82      0.86      0.84       520\n",
            "\n",
            "    accuracy                           0.88      5000\n",
            "   macro avg       0.88      0.87      0.87      5000\n",
            "weighted avg       0.88      0.88      0.87      5000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wc0CZrufyo75",
        "colab_type": "text"
      },
      "source": [
        "# **After Preprocessing Do LR**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjK7sUazmJNE",
        "colab_type": "code",
        "outputId": "c9251668-1ceb-432d-b1d2-48082cb392a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "training_size = len(preprocessed_1_X_train)\n",
        "testing_size = len(preprocessed_1_X_test)\n",
        "size_A = len(X_train[0])\n",
        "preprocessed_1_X_train = X_train.reshape(training_size, size_A)\n",
        "preprocessed_1_X_test = X_test.reshape(testing_size, size_A)\n",
        "\n",
        "clf_A = LogisticRegression(C=50,\n",
        "                         multi_class='multinomial',\n",
        "                         penalty='l2', solver='saga', tol=0.1)\n",
        "\n",
        "clf_A.fit(preprocessed_1_X_train, y_train)\n",
        "clear_output()\n",
        "y_predict = clf.predict(preprocessed_1_X_test)\n",
        "\n",
        "print(f'normal score: {accuracy_score(y_test,clf.predict(preprocessed_1_X_test))}')\n",
        "\n",
        "# print(f'normal score: {accuracy_score(y_test, clf.predict(X_test))}')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-13-897b8dccf52e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtraining_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_1_X_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtesting_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_1_X_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msize_A\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpreprocessed_1_X_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_A\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpreprocessed_1_X_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize_A\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'preprocessed_1_X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVVZqsJixlTI",
        "colab_type": "code",
        "outputId": "b65b1555-6983-400f-d73a-1d5aba2a5f83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "y_predict = clf_A.predict(preprocessed_1_X_test)\n",
        "cm = confusion_matrix(y_test, y_predict)\n",
        "\n",
        "print(cm)\n",
        "print(classification_report(y_test, y_predict, \n",
        "                            target_names=['0','1','2','3','4','5','6','7','8','9']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 958    0    4    8    3    6    8    3   10    1]\n",
            " [   0 1098    5    2    2   10    0    4    4    2]\n",
            " [   8   13  870   11   24    6   13   16   24    6]\n",
            " [   1    9   30  905    2   31    6   14   12   22]\n",
            " [   3    7    9    0  914    1    7    2    4   33]\n",
            " [   7   10    4   41   19  720   19    1   30   12]\n",
            " [   7    4    9    0    6   13  968    0    6    1]\n",
            " [   3    7    9    3   17    3    0  977    5   46]\n",
            " [   6   27   21   25    3   39   22    5  784   12]\n",
            " [  10    4    8   18   21    5    0   29    8  875]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.96      0.96      1001\n",
            "           1       0.93      0.97      0.95      1127\n",
            "           2       0.90      0.88      0.89       991\n",
            "           3       0.89      0.88      0.89      1032\n",
            "           4       0.90      0.93      0.92       980\n",
            "           5       0.86      0.83      0.85       863\n",
            "           6       0.93      0.95      0.94      1014\n",
            "           7       0.93      0.91      0.92      1070\n",
            "           8       0.88      0.83      0.86       944\n",
            "           9       0.87      0.89      0.88       978\n",
            "\n",
            "    accuracy                           0.91     10000\n",
            "   macro avg       0.91      0.90      0.90     10000\n",
            "weighted avg       0.91      0.91      0.91     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEnoHQjTJhm1",
        "colab_type": "code",
        "outputId": "7fcf36a0-ff23-4a4b-b67f-150107856f72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "training_size = len(X_train)\n",
        "X_train = X_train.reshape(training_size, 784)\n",
        "X_test = X_test.reshape(training_size, 784)\n",
        "clf = LogisticRegression(C=50 / training_size,\n",
        "                         multi_class='multinomial',\n",
        "                         penalty='l2', solver='saga', tol=0.1)\n",
        "\n",
        "# clf_s = LogisticRegression(C=50 / training_size ,\n",
        "#                          multi_class='multinomial',\n",
        "#                          penalty='l2', solver='saga', tol=0.1)\n",
        "\n",
        "# X_train, X_test, y_train, y_test = split_set()\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "clear_output()\n",
        "print(f'after preprocessed score: {accuracy_score(y_test,clf.predict(X_test))}')\n",
        "\n",
        "# scaler = StandardScaler()\n",
        "# scaler.fit(X)\n",
        "# X_scaled = scaler.transform(X)\n",
        "\n",
        "# X_train_scaled, X_test, y_train, y_test = split_set('scale')\n",
        "\n",
        "# clf_s.fit(X_train_scaled, y_train)\n",
        "# print(f'standard scaled score: {accuracy_score(y_test,clf.predict(X_test))}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "normal score: 0.9088\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m36s83lAlmID",
        "colab_type": "code",
        "outputId": "fcb1249e-ff5e-4d44-8898-01ad497cf060",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "training_size_1 = len(X_svc_grads_train)\n",
        "testing_size_1 = len(X_svc_grads_test)\n",
        "#X_train = X_train.reshape(training_size_1, 784)\n",
        "#X_test = X_test.reshape(testing_size_1, 784)\n",
        "\n",
        "clf = LogisticRegression(C=50,\n",
        "                         multi_class='multinomial',\n",
        "                         penalty='l2', solver='saga', tol=0.1)\n",
        "\n",
        "clf.fit(X_svc_grads_train, y_train)\n",
        "clear_output()\n",
        "\n",
        "print(f'normal score: {accuracy_score(y_test,clf.predict(X_svc_grads_test))}')\n",
        "\n",
        "# print(f'normal score: {accuracy_score(y_test, clf.predict(X_test))}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "normal score: 0.0865\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkkSbq-zliPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_svc_grads_train.shape)\n",
        "print(X_svc_grads_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKOwZueHX3O2",
        "colab_type": "text"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXgU5jg5X6kn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(X, Y, model, default_param, param_grid, cv, save, filename):\n",
        "    \n",
        "    clf = model(**default_param)\n",
        "    estimator = GridSearchCV(clf, param_grid, cv=cv, n_jobs=-1)\n",
        "    \n",
        "    estimator.fit(X, Y)\n",
        "    \n",
        "    if save:\n",
        "        joblib.dump(estimator, filename)\n",
        "        \n",
        "    return estimator\n",
        "\n",
        "def get_model(model, filename, param_grid=dict(), cv=6, X=None, Y=None, default_param=dict(), force_training=False, save=True):\n",
        "    \n",
        "    path = pathlib.Path(filename)\n",
        "    estimator = None\n",
        "    \n",
        "    if force_training == True:\n",
        "        estimator = train_model(X, Y, model, default_param, param_grid, cv, save, filename)\n",
        "    else:\n",
        "        if path.exists(): # if file exists, just load that.\n",
        "            estimator = joblib.load(filename)\n",
        "        else:\n",
        "            estimator = train_model(X, Y, model, default_param, param_grid, cv, save, filename)\n",
        "            \n",
        "    return estimator\n",
        "\n",
        "def get_model_without_gridsearch(model, filename, default_param=dict(), X=None, Y=None, save=True):\n",
        "    \n",
        "    if pathlib.Path(filename).exists():\n",
        "        estimator = joblib.load(filename)\n",
        "    else:\n",
        "        estimator = model(**default_param)\n",
        "        estimator.fit(X, Y)\n",
        "        if save:\n",
        "            joblib.dump(estimator, filename)\n",
        "        \n",
        "    return estimator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Hzz4urWeyNc",
        "colab_type": "text"
      },
      "source": [
        "# **Zero Padding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJ4QRjN9X6-j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def zero_padding(images, n=1):\n",
        "    \"\"\"\n",
        "    zero-padding to image.\n",
        "    add additional edge which has value of 0\n",
        "    \n",
        "    Arguments:\n",
        "    ---------------------\n",
        "    - images: training dataset images. maybe (60000, 28, 28)\n",
        "    - n: how many padding do you want? in other word, how many edge do you want to insert?\n",
        "    \n",
        "    Returns:\n",
        "    ---------------------\n",
        "    - images_padded: padded images. (60000, 30, 30) or other shape.\n",
        "    \"\"\"\n",
        "    \n",
        "    # number of training examples. 60000. if you use test data, 10000.\n",
        "    m = images.shape[0]\n",
        "    print(m)\n",
        "    # define larger size of window than size of images. maybe (60000, 30, 30), (60000, 32, 32)\n",
        "    images_padded = np.zeros((m, images.shape[1] + 2 * n, images.shape[2] + 2 * n))\n",
        "    \n",
        "    # insert image in the middle of this window.\n",
        "    images_padded[:, n : images_padded.shape[1] - n, n : images_padded.shape[2] - n] = images\n",
        "    \n",
        "    return images_padded\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rg9hpGgX7BE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def x_gradient_slice(images_slice):\n",
        "    \"\"\"\n",
        "    find gradient(in korean, 기울기 또는 미분값) for part of images.\n",
        "    \n",
        "    Arguments:\n",
        "    ----------------------\n",
        "    - images_slice: small window extracted from images. (60000, 7, 7)\n",
        "    \n",
        "    Returns:\n",
        "    ----------------------\n",
        "    - grad: x-axis-oriented gradient (in korean, x 축 방향 기울기)p\n",
        "    \"\"\"\n",
        "    \n",
        "    x_gradient_filter = np.array([\n",
        "        [-1,  0,  1],\n",
        "        [-1,  0,  1],\n",
        "        [-1,  0,  1],\n",
        "    ])\n",
        "    \n",
        "    # reshape for broadcasting.\n",
        "    x_gradient_filter = x_gradient_filter.reshape(1, 3, 3)\n",
        "    \n",
        "    # element-wise compute. compute gradient\n",
        "    temp = np.multiply(images_slice, x_gradient_filter)\n",
        "    grad = np.sum(temp, axis=(1, 2))\n",
        "    \n",
        "    return grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDfd1qwUX7DZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def x_gradient(images):\n",
        "    \n",
        "    # some useful variables.\n",
        "    m = images.shape[0]\n",
        "    width = images.shape[1]\n",
        "    height = images.shape[2]\n",
        "    \n",
        "    # define placeholder to store gradients.\n",
        "    x_grads = np.zeros((m, width - 2, height - 2))\n",
        "    \n",
        "    # slice image into small size window, then compute gradient.\n",
        "    for w in range(1, width - 1):\n",
        "        for h in range(1, height - 1):\n",
        "            images_slice = images[:, w - 1 : w + 2, h - 1 : h + 2]\n",
        "            x_grads[:, w - 1, h - 1] = x_gradient_slice(images_slice)\n",
        "            \n",
        "    return x_grads"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFaMIlYeX7Ft",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def y_gradient_slice(images_slice):\n",
        "    \"\"\"\n",
        "    find gradient(in korean, 기울기 또는 미분값) for part of images.\n",
        "    \n",
        "    Arguments:\n",
        "    ----------------------\n",
        "    - images_slice: small window extracted from images. (60000, 7, 7)\n",
        "    \n",
        "    Returns:\n",
        "    ----------------------\n",
        "    - grad: y-axis-oriented gradient (in korean, y 축 방향 기울기)\n",
        "    \"\"\"\n",
        "    \n",
        "    y_gradient_filter = np.array([\n",
        "        [-1, -1, -1],\n",
        "        [ 0,  0,  0],\n",
        "        [ 1,  1,  1],\n",
        "    ])\n",
        "    \n",
        "    # reshape for broadcasting.\n",
        "    y_gradient_filter = y_gradient_filter.reshape(1, 3, 3)\n",
        "    \n",
        "    # element-wise compute. compute gradient\n",
        "    temp = np.multiply(images_slice, y_gradient_filter)\n",
        "    grad = np.sum(temp, axis=(1, 2))\n",
        "    \n",
        "    return grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDFzVlxUX7H_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def y_gradient(images):\n",
        "    \n",
        "    # some useful variables.\n",
        "    m = images.shape[0]\n",
        "    width = images.shape[1]\n",
        "    height = images.shape[2]\n",
        "    \n",
        "    # define placeholder to store gradients.\n",
        "    y_grads = np.zeros((m, width - 2, height - 2))\n",
        "    \n",
        "    # slice image into small size window, then compute gradient.\n",
        "    for w in range(1, width - 1):\n",
        "        for h in range(1, height - 1):\n",
        "            images_slice = images[:, w - 1 : w + 2, h - 1 : h + 2]\n",
        "            y_grads[:, w - 1, h - 1] = y_gradient_slice(images_slice)\n",
        "            \n",
        "    return y_grads"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yJFg_jFX7KS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_average_grads(x_grads, y_grads, grid=7):\n",
        "    \n",
        "    \n",
        "    assert(x_grads.shape == y_grads.shape)\n",
        "    \n",
        "    # some useful variables.\n",
        "    m = x_grads.shape[0]\n",
        "    width = x_grads.shape[1]\n",
        "    height = x_grads.shape[2]\n",
        "    \n",
        "    # I define these variables to slicing images conveniently.\n",
        "    w_step = width // grid  # w_step = 4\n",
        "    h_step = height // grid # h_step = 4\n",
        "    \n",
        "    # placeholder for storing average of gradients, 빈공간 만들기\n",
        "    x_avg_grads = np.zeros((m, width // w_step, height // h_step))\n",
        "    y_avg_grads = np.zeros((m, width // w_step, height // h_step))\n",
        "    \n",
        "    for w in range(0, width, w_step):\n",
        "        for h in range(0, height, h_step):\n",
        "            # slicing gradients into small part.\n",
        "            x_grads_slice = x_grads[:, w : w + w_step, h : h + h_step]\n",
        "            y_grads_slice = y_grads[:, w : w + w_step, h : h + h_step]\n",
        "            \n",
        "            assert(x_grads_slice.shape == y_grads_slice.shape == (m, width // grid, height // grid))\n",
        "            \n",
        "            # compute mean of gradients of part of image\n",
        "            x_avg_grads[:, w // w_step, h // h_step] = np.mean(x_grads_slice, axis=(1, 2))\n",
        "            y_avg_grads[:, w // w_step, h // h_step] = np.mean(y_grads_slice, axis=(1, 2))\n",
        "            \n",
        "    return x_avg_grads, y_avg_grads"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COnjlExfX7M1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def average_gradients_grid(images, grid=7, padding=1, normalize=True):\n",
        "    \n",
        "    images = np.copy(images)\n",
        "    \n",
        "    m = images.shape[0]\n",
        "    \n",
        "    # normalize\n",
        "    if normalize:\n",
        "        images_norm = images / 255\n",
        "    else:\n",
        "        images_norm = images\n",
        "    \n",
        "    # thresholding\n",
        "    images_norm[images_norm >= 0.2] = 1\n",
        "    images_norm[images_norm < 0.2] = 0\n",
        "    \n",
        "    # zero padding\n",
        "    images_padded = zero_padding(images_norm, padding)\n",
        "    \n",
        "    # number of features = grid^2 * 2\n",
        "    features = np.zeros((m, (grid ** 2) * 2))\n",
        "\n",
        "    # compute x-axis gradient, y-axis gradient\n",
        "    x_grads = x_gradient(images_padded)\n",
        "    y_grads = y_gradient(images_padded)\n",
        "    \n",
        "    # compute average of gradient (grid 7x7)\n",
        "    x_avg_grads, y_avg_grads = get_average_grads(x_grads, y_grads, grid)\n",
        "    \n",
        "    assert(x_avg_grads.shape == y_avg_grads.shape == (m, grid, grid))\n",
        "    \n",
        "    # flatten\n",
        "    x_features = x_avg_grads.reshape(m, -1)\n",
        "    y_features = y_avg_grads.reshape(m, -1)\n",
        "    \n",
        "    features[:, : grid ** 2] = x_features\n",
        "    features[:, grid ** 2 :] = y_features\n",
        "    \n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxZ3Uv-FZ_KY",
        "colab_type": "code",
        "outputId": "d34aa8df-5945-4c23-ad4e-d829707efff2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        }
      },
      "source": [
        "X_train = X_train.reshape(training_size, 28, 28)\n",
        "X_test = X_test.reshape(testing_size, 28, 28)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-118-707d2af8176e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimages_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimages_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 23520000 into shape (10000,28,28)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tx0c6rEJi3pB",
        "colab_type": "code",
        "outputId": "3f5cde23-683e-4f09-ae89-84b212abab1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 28, 28)\n",
            "(30000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Agfhmpo2X7O_",
        "colab_type": "code",
        "outputId": "7e226cd6-8f63-4d4f-922d-7c6959bc538b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        }
      },
      "source": [
        "preprocessed_1_X_train = average_gradients_grid(X_train)\n",
        "preprocessed_1_X_test = average_gradients_grid(X_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "MemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-121-ba2699b0f8dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpreprocessed_1_X_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maverage_gradients_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpreprocessed_1_X_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maverage_gradients_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m<ipython-input-117-2b1b6a572d38>\u001b[0m in \u001b[0;36maverage_gradients_grid\u001b[1;34m(images, grid, padding, normalize)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# normalize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mimages_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mimages_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mMemoryError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dQItitpX7RY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(preprocessed_1_X_train.shape)\n",
        "print(preprocessed_1_X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfIttE8BX7bl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mlgUPxi154zv",
        "colab_type": "text"
      },
      "source": [
        "# **Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DkeeiQNUY0A",
        "colab_type": "text"
      },
      "source": [
        "# **New Grid Search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfXA03NxUc9L",
        "colab_type": "code",
        "outputId": "c9e0b149-9e37-4e9d-a3c0-1233e564a7b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "import pathlib\n",
        "from sklearn.externals import joblib\n",
        "\n",
        "param_grid = [\n",
        "    {\n",
        "        'penalty': ['l1', 'l2'],\n",
        "        'C': [1e-4, 1e-4, 1e-3, 1e-2, 1e-1, 1, 1000], # 1000 means no regularization\n",
        "        'solver':['saga']\n",
        "    }\n",
        "]\n",
        "\n",
        "# load or train model.\n",
        "clf_logs_1_1 = get_model(LogisticRegression, 'C:/datas/logistic_1.model_data', param_grid, 3, X=preprocessed_1_X_train, Y=y_train, default_param=dict(solver='lbfgs'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "c:\\users\\김윤기\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n",
            "c:\\users\\김윤기\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "c:\\users\\김윤기\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages\\sklearn\\linear_model\\sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  \"the coef_ did not converge\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCdcq9-3WgND",
        "colab_type": "code",
        "outputId": "f076cbb7-2855-4e9b-d50f-06e685888a2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "param_logs_1_1 = clf_logs_1_1.best_params_\n",
        "print(param_logs_1_1)\n",
        "\n",
        "# get best logistic regression we found on grid search. This contain best parameters.\n",
        "logs_1_1 = clf_logs_1_1.best_estimator_\n",
        "\n",
        "# get best accuracy on training set\n",
        "print('Accuracy on training set:')\n",
        "print(clf_logs_1_1.best_score_)\n",
        "\n",
        "# compute accuracy on test set using best logistic regression\n",
        "print('Accuracy on test set:')\n",
        "print(logs_1_1.score(preprocessed_1_X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'C': 1000, 'penalty': 'l1', 'solver': 'saga'}\n",
            "Accuracy on training set:\n",
            "0.8851\n",
            "Accuracy on test set:\n",
            "0.894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wx3kOs08UcN_",
        "colab_type": "text"
      },
      "source": [
        "# **End New Grid Search**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9dkZn6iNdxV",
        "colab_type": "text"
      },
      "source": [
        "# **Grid Search After Preprocessing**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4uQ9eR2yQct",
        "colab_type": "code",
        "outputId": "ac46dadd-2505-437a-a1ef-6e69f1f5dbda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(X_svc_grads_train.shape)\n",
        "print(X_svc_grads_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 98)\n",
            "(10000, 98)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bV6qWe2XK5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(preprocessed_1_X_train.shape)\n",
        "print(preprocessed_1_X_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJVgiypruoMP",
        "colab_type": "code",
        "outputId": "f9e38a29-8cd5-45b6-d07d-c2e4b7e04b1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        }
      },
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "f1=make_scorer(f1_score, average='macro')\n",
        "params = [{'penalty':['l1','l2'], 'C':[1000, 500, 100, 50, 10], 'solver':['saga']}]\n",
        "grid_search_clf_processed = GridSearchCV(LogisticRegression(random_state=42, max_iter=30, tol=1e-3),\n",
        "                  param_grid=params,\n",
        "                  scoring=f1,\n",
        "                  cv=5)\n",
        "\n",
        "# print(grid_search_clf)\n",
        "grid_search_clf_processed.fit(preprocessed_1_X_train, y_train)\n",
        "clear_output()\n",
        "elaspe_time = time.time() - start_time\n",
        "print('Elapse time :%.1f' % (elaspe_time),'sec')\n",
        "print('Best Parameter :', grid_search_clf_processed.best_params_)\n",
        "cv_result_processed = grid_search_clf_processed.cv_results_\n",
        "for mean_score, params in zip(cv_result_processed['mean_test_score'], cv_result_processed['params']):\n",
        "  print(mean_score, params)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elapse time :188.6 sec\n",
            "Best Parameter : {'C': 50, 'penalty': 'l2', 'solver': 'saga'}\n",
            "0.8938192641396682 {'C': 1000, 'penalty': 'l1', 'solver': 'saga'}\n",
            "0.8938192641396682 {'C': 1000, 'penalty': 'l2', 'solver': 'saga'}\n",
            "0.8938192641396682 {'C': 500, 'penalty': 'l1', 'solver': 'saga'}\n",
            "0.8938192641396682 {'C': 500, 'penalty': 'l2', 'solver': 'saga'}\n",
            "0.8938192641396682 {'C': 100, 'penalty': 'l1', 'solver': 'saga'}\n",
            "0.8938192641396682 {'C': 100, 'penalty': 'l2', 'solver': 'saga'}\n",
            "0.8938192641396682 {'C': 50, 'penalty': 'l1', 'solver': 'saga'}\n",
            "0.8938200230751925 {'C': 50, 'penalty': 'l2', 'solver': 'saga'}\n",
            "0.8933114014517357 {'C': 10, 'penalty': 'l1', 'solver': 'saga'}\n",
            "0.8932189969677249 {'C': 10, 'penalty': 'l2', 'solver': 'saga'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kSXIiuQun78",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = split_set()\n",
        "print(X_train.shape)\n",
        "\n",
        "\n",
        "lg_model  = LogisticRegression(C=0.1, penalty='l1', random_state = 77)\n",
        "lg_model.fit(X_train,y_train)\n",
        "\n",
        "y_predict = lg_model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_predict)\n",
        "print(classification_report(y_test, y_predict, \n",
        "                            target_names=['0','1','2','3','4','5','6','7','8','9']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0VonUn-unhU",
        "colab_type": "text"
      },
      "source": [
        "# **Grid Search**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXnPxjXK1gpL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train\n",
        "y_train = y_train\n",
        "X_test = X_test\n",
        "y_test = y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf644aMFLm_H",
        "colab_type": "code",
        "outputId": "34caeff2-3870-4aad-c311-7871e74d5890",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "start_time_1 = time()\n",
        "f1_1=make_scorer(f1_score, average='macro')\n",
        "params = [{'penalty':['l1','l2'], 'C':[10,1,0.1,0.01,0.001], 'solver':['saga']}]\n",
        "grid_search_clf = GridSearchCV(LogisticRegression(random_state=42, max_iter=30, tol=1e-3),\n",
        "                  param_grid=params,\n",
        "                  scoring=f1_1,\n",
        "                  cv=5)\n",
        "\n",
        "# print(grid_search_clf)\n",
        "grid_search_clf.fit(X_train, y_train)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-31-9fc22a20fd65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mgrid_search_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Elapse time :%.f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sec'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'str' and 'float'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya4bu-FfL2dA",
        "colab_type": "code",
        "outputId": "9d6c2bc7-70ab-4d5a-d205-8d721cdd275c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "start = time.time()\n",
        "print('time : %.1f' %(time.time() - start))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time : 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWFUFXgQKxaE",
        "colab_type": "code",
        "outputId": "f1e74c8b-568e-438b-8558-f33aacb5c14a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "cv_result = grid_search_clf.cv_results_\n",
        "for mean_score, params in zip(cv_result['mean_test_score'], cv_result['params']):\n",
        "  print(mean_score, params)\n",
        "grid_search_clf.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9002521286056621 {'C': 10, 'penalty': 'l1', 'solver': 'saga'}\n",
            "0.9002521286056621 {'C': 10, 'penalty': 'l2', 'solver': 'saga'}\n",
            "0.9002521286056621 {'C': 1, 'penalty': 'l1', 'solver': 'saga'}\n",
            "0.9002521286056621 {'C': 1, 'penalty': 'l2', 'solver': 'saga'}\n",
            "0.9001470563977063 {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
            "0.9002521286056621 {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}\n",
            "0.901636178422903 {'C': 0.01, 'penalty': 'l1', 'solver': 'saga'}\n",
            "0.9002521286056621 {'C': 0.01, 'penalty': 'l2', 'solver': 'saga'}\n",
            "0.8949072862116091 {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
            "0.9002521286056621 {'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 0.01, 'penalty': 'l1', 'solver': 'saga'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nByDdDmw8t5W",
        "colab_type": "code",
        "outputId": "e6d810ba-53ed-4eef-eb26-11a0e9fa02b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "cv_result = grid_search_clf.cv_results_\n",
        "for mean_score, params in zip(cv_result['mean_test_score'], cv_result['params']):\n",
        "  print(mean_score, params)\n",
        "grid_search_clf.best_params_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9002521286056621 {'C': 10, 'penalty': 'l1', 'solver': 'saga'}\n",
            "0.9002521286056621 {'C': 10, 'penalty': 'l2', 'solver': 'saga'}\n",
            "0.9002521286056621 {'C': 1, 'penalty': 'l1', 'solver': 'saga'}\n",
            "0.9002521286056621 {'C': 1, 'penalty': 'l2', 'solver': 'saga'}\n",
            "0.9001470563977063 {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'}\n",
            "0.9002521286056621 {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'}\n",
            "0.901636178422903 {'C': 0.01, 'penalty': 'l1', 'solver': 'saga'}\n",
            "0.9002521286056621 {'C': 0.01, 'penalty': 'l2', 'solver': 'saga'}\n",
            "0.8949072862116091 {'C': 0.001, 'penalty': 'l1', 'solver': 'saga'}\n",
            "0.9002521286056621 {'C': 0.001, 'penalty': 'l2', 'solver': 'saga'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 0.01, 'penalty': 'l1', 'solver': 'saga'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfWqGzT1_mN2",
        "colab_type": "code",
        "outputId": "8e31e677-a085-4b24-c2b2-270a32239e6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "y_predict = grid_search_clf.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_predict)\n",
        "print(classification_report(y_test, y_predict, \n",
        "                            target_names=['0','1','2','3','4','5','6','7','8','9']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96      1001\n",
            "           1       0.93      0.97      0.95      1127\n",
            "           2       0.90      0.88      0.89       991\n",
            "           3       0.88      0.87      0.88      1032\n",
            "           4       0.90      0.91      0.90       980\n",
            "           5       0.88      0.81      0.84       863\n",
            "           6       0.94      0.95      0.95      1014\n",
            "           7       0.94      0.92      0.93      1070\n",
            "           8       0.86      0.83      0.84       944\n",
            "           9       0.86      0.90      0.88       978\n",
            "\n",
            "    accuracy                           0.90     10000\n",
            "   macro avg       0.90      0.90      0.90     10000\n",
            "weighted avg       0.90      0.90      0.90     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxngLEJi80Ue",
        "colab_type": "text"
      },
      "source": [
        "preprocessing comparision "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7vwU-7A604u",
        "colab_type": "code",
        "outputId": "00df60d1-5590-4dfa-d9e8-d76ffab3f790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "X_train, X_test, y_train, y_test = split_set()\n",
        "print(X_train.shape)\n",
        "\n",
        "\n",
        "lg_model  = LogisticRegression(C=0.1, penalty='l1', random_state = 77)\n",
        "lg_model.fit(X_train,y_train)\n",
        "\n",
        "y_predict = lg_model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_predict)\n",
        "print(classification_report(y_test, y_predict, \n",
        "                            target_names=['0','1','2','3','4','5','6','7','8','9']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8000, 784)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95       196\n",
            "           1       0.95      0.99      0.97       227\n",
            "           2       0.86      0.86      0.86       206\n",
            "           3       0.84      0.87      0.85       202\n",
            "           4       0.89      0.91      0.90       196\n",
            "           5       0.83      0.77      0.80       178\n",
            "           6       0.91      0.91      0.91       192\n",
            "           7       0.90      0.88      0.89       206\n",
            "           8       0.84      0.83      0.84       195\n",
            "           9       0.84      0.82      0.83       202\n",
            "\n",
            "    accuracy                           0.88      2000\n",
            "   macro avg       0.88      0.88      0.88      2000\n",
            "weighted avg       0.88      0.88      0.88      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVQUwHag9CPo",
        "colab_type": "code",
        "outputId": "dbe07cf1-9742-44b7-e520-32bc286cc9b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "#X_train, X_test, y_train, y_test = split_set()\n",
        "#print(X_train.shape)\n",
        "\n",
        "X_train_reshape = X_train_reshape.reshape(10000,196)\n",
        "lg_model  = LogisticRegression(C=0.1, penalty='l1', random_state = 77)\n",
        "lg_model.fit(X_train_reshape,y_train)\n",
        "\n",
        "y_predict = lg_model.predict(X_train_reshape)\n",
        "cm = confusion_matrix(y_train, y_predict)\n",
        "print(classification_report(y_test, y_predict, \n",
        "                            target_names=['0','1','2','3','4','5','6','7','8','9']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       980\n",
            "           1       0.11      1.00      0.20      1135\n",
            "           2       0.00      0.00      0.00      1032\n",
            "           3       0.00      0.00      0.00      1010\n",
            "           4       0.00      0.00      0.00       982\n",
            "           5       0.00      0.00      0.00       892\n",
            "           6       0.00      0.00      0.00       958\n",
            "           7       0.00      0.00      0.00      1028\n",
            "           8       0.00      0.00      0.00       974\n",
            "           9       0.00      0.00      0.00      1009\n",
            "\n",
            "    accuracy                           0.11     10000\n",
            "   macro avg       0.01      0.10      0.02     10000\n",
            "weighted avg       0.01      0.11      0.02     10000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbvknXWbB4aY",
        "colab_type": "code",
        "outputId": "3a7fa3f3-07bb-446f-95f3-22768dc1f1ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "X_train_norm_re = X_train_norm_re.reshape(8000,784)\n",
        "X_test_norm_re = X_test_norm_re.reshape(2000,784)\n",
        "\n",
        "lg_model  = LogisticRegression(C=0.1, penalty='l1', random_state = 77)\n",
        "lg_model.fit(X_train_norm_re,y_train)\n",
        "\n",
        "y_predict = lg_model.predict(X_test_norm_re)\n",
        "cm = confusion_matrix(y_test, y_predict)\n",
        "print(classification_report(y_test, y_predict, \n",
        "                            target_names=['0','1','2','3','4','5','6','7','8','9']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       196\n",
            "           1       0.90      0.98      0.94       227\n",
            "           2       0.91      0.83      0.87       206\n",
            "           3       0.91      0.88      0.89       202\n",
            "           4       0.83      0.89      0.86       196\n",
            "           5       0.91      0.80      0.85       178\n",
            "           6       0.93      0.94      0.94       192\n",
            "           7       0.91      0.91      0.91       206\n",
            "           8       0.84      0.86      0.85       195\n",
            "           9       0.83      0.84      0.84       202\n",
            "\n",
            "    accuracy                           0.89      2000\n",
            "   macro avg       0.89      0.89      0.89      2000\n",
            "weighted avg       0.89      0.89      0.89      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQKhrW-LBHor",
        "colab_type": "code",
        "outputId": "41a9ff59-ba4a-461d-91d7-1637aa9a4417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "#X_train_b_or_w\n",
        "#X_test_b_or_w\n",
        "\n",
        "lg_model  = LogisticRegression(C=0.001, 0.01, 0.1, 1, 10 penalty='l2', random_state = 42)\n",
        "lg_model.fit(X_train_b_or_w,y_train)\n",
        "\n",
        "y_predict = lg_model.predict(X_test_b_or_w)\n",
        "cm = confusion_matrix(y_test, y_predict)\n",
        "print(classification_report(y_test, y_predict, \n",
        "                            target_names=['0','1','2','3','4','5','6','7','8','9']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       196\n",
            "           1       0.91      0.98      0.94       227\n",
            "           2       0.92      0.84      0.88       206\n",
            "           3       0.88      0.84      0.86       202\n",
            "           4       0.85      0.89      0.87       196\n",
            "           5       0.90      0.80      0.85       178\n",
            "           6       0.92      0.94      0.93       192\n",
            "           7       0.91      0.88      0.90       206\n",
            "           8       0.79      0.87      0.83       195\n",
            "           9       0.84      0.84      0.84       202\n",
            "\n",
            "    accuracy                           0.89      2000\n",
            "   macro avg       0.89      0.89      0.89      2000\n",
            "weighted avg       0.89      0.89      0.89      2000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzoKj4Y0C63O",
        "colab_type": "text"
      },
      "source": [
        "# **Show Score Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29XU8CABC6bz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# NAMES\n",
        "# grid_search_clf\n",
        "# clf\n",
        "# clf.s\n",
        "\n",
        "y_predict = #MODEL NAME#.predict(X_test)\n",
        "#NAME# = confusion_matrix(y_test, y_predict)\n",
        "print(classification_report(y_test, y_predict, \n",
        "                            target_names = [str(range(0, 10))]))\n",
        "\n",
        "# cv_result = #MODEL NAME#.cv_results_\n",
        "\n",
        "# cvres = new_lg_model.best_params_  # \n",
        "# for mean_score, params in zip(cv_result['mean_test_score'], cv_result['params']):\n",
        "#   print(np.sqrt(mean_score), params)    # '0.818125 {'C': 0.1, 'penalty': 'l1'}'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma_txMdfOnpL",
        "colab_type": "text"
      },
      "source": [
        "# **Show Score | Params**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qr_UlnFOMl8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NAME#.best_estimator_\n",
        "\n",
        "cv_result = #NAME#.cv_results_\n",
        "# cv_result = #NAME#.best_params_\n",
        "for mean_score, params in zip(cv_result['mean_test_score'], cv_result['params']):\n",
        "  print(mean_score, params)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}